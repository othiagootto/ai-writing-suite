import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

const OPENAI_API_KEY = Deno.env.get("OPENAI_API_KEY");
const ANTHROPIC_API_KEY = Deno.env.get("ANTHROPIC_API_KEY");

const TOOL_PROMPTS: Record<string, string> = {
  detector: `You are an expert AI content detector. Analyze the provided text and determine the likelihood it was generated by an AI language model.

Evaluate based on: text predictability, sentence uniformity, linguistic patterns.

Respond with valid JSON:
{"score": <0-100>, "summary": "<analysis>", "highlights": [{"start": <int>, "end": <int>, "type": "ai_detected", "confidence": <0-1>, "message": "<why>"}], "breakdown": {"predictability": <0-100>, "uniformity": <0-100>, "patterns": <0-100>}}`,

  plagiarism: `You are an originality analyzer. Analyze text for signs of unoriginal content.
NOTE: This is heuristic analysis, not factual comparison against published sources.

Respond with valid JSON:
{"score": <0-100 originality>, "summary": "<analysis>", "highlights": [{"start": <int>, "end": <int>, "type": "potential_plagiarism", "confidence": <0-1>, "message": "<why>"}], "suggestions": ["<suggestion>"]}`,

  humanizer: `You are a text humanizer. Rewrite AI-generated text to read like natural human writing.
MODE: {mode}
- "light": Minimal changes, fix obvious AI patterns. Keep ~90% of original.
- "auto": Balanced rewrite. Vary structure, add natural flow. Keep ~70%.
- "bypass": Heavy rewrite. Restructure completely. Keep meaning, change ~60%.

Respond with valid JSON:
{"result": "<humanized text>", "changes_made": <number>, "similarity_score": <0-100>}`,

  paraphraser: `You are a professional paraphraser. Rewrite with specified tone and intensity.
TONE: {tone} | INTENSITY: {intensity}
Tones: academic, casual, professional, neutral, humanize, remove-plagiarism
Intensities: minimum (~20% change), moderate (~50%), maximum (~80%)

Respond with valid JSON:
{"result": "<paraphrased text>", "words_changed_percent": <number>}`,

  grammar: `You are an expert grammar checker. Analyze text for errors and improvements.
Check: grammar, punctuation, spelling, style, word choice.

Respond with valid JSON:
{"corrected_text": "<full corrected text>", "corrections": [{"original": "<wrong>", "corrected": "<fixed>", "type": "grammar|punctuation|spelling|style|word_choice", "message": "<explanation>"}], "score": <0-100>, "summary": "<N errors found, N suggestions>"}`,

  summarizer: `You are a summarization expert. Create a concise summary.
LENGTH: {length} (short: 1-2 sentences, medium: 3-5 sentences, long: 1-2 paragraphs)

Respond with valid JSON:
{"result": "<summary>", "key_points": ["<point>"], "original_word_count": <n>, "summary_word_count": <n>, "compression_ratio": "<percent>"}`,

  citation: `You are a citation generator. Generate a properly formatted citation.
FORMAT: {format} (apa, mla, chicago, harvard)

Respond with valid JSON:
{"citation": "<formatted citation>", "format": "{format}", "in_text": "<in-text version>", "notes": "<assumptions>"}`,
};

function buildPrompt(tool: string, options: Record<string, string>): string {
  let prompt = TOOL_PROMPTS[tool] || "";
  for (const [key, value] of Object.entries(options)) {
    prompt = prompt.replaceAll(`{${key}}`, value);
  }
  return prompt;
}

async function callOpenAI(systemPrompt: string, userInput: string) {
  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${OPENAI_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: "gpt-4o",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userInput },
      ],
      response_format: { type: "json_object" },
      max_tokens: 4096,
      temperature: 0.7,
    }),
  });

  if (!response.ok) {
    const err = await response.text();
    throw new Error(`OpenAI error: ${response.status} - ${err}`);
  }

  const data = await response.json();
  return {
    content: data.choices[0].message.content,
    tokensUsed: data.usage?.total_tokens || 0,
    provider: "openai" as const,
  };
}

async function callAnthropic(systemPrompt: string, userInput: string) {
  const response = await fetch("https://api.anthropic.com/v1/messages", {
    method: "POST",
    headers: {
      "x-api-key": ANTHROPIC_API_KEY!,
      "anthropic-version": "2023-06-01",
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: "claude-sonnet-4-5-20250929",
      max_tokens: 4096,
      system: systemPrompt + "\n\nIMPORTANT: Always respond with valid JSON only, no markdown or extra text.",
      messages: [{ role: "user", content: userInput }],
    }),
  });

  if (!response.ok) {
    const err = await response.text();
    throw new Error(`Anthropic error: ${response.status} - ${err}`);
  }

  const data = await response.json();
  const textBlock = data.content.find((b: { type: string }) => b.type === "text");
  return {
    content: textBlock?.text || "{}",
    tokensUsed: (data.usage?.input_tokens || 0) + (data.usage?.output_tokens || 0),
    provider: "anthropic" as const,
  };
}

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response("ok", { headers: corsHeaders });
  }

  try {
    const supabaseClient = createClient(
      Deno.env.get("SUPABASE_URL") ?? "",
      Deno.env.get("SUPABASE_ANON_KEY") ?? "",
      { global: { headers: { Authorization: req.headers.get("Authorization")! } } }
    );

    const { data: { user }, error: authError } = await supabaseClient.auth.getUser();
    if (authError || !user) {
      return new Response(JSON.stringify({ error: "Unauthorized" }), {
        status: 401,
        headers: { ...corsHeaders, "Content-Type": "application/json" },
      });
    }

    const { tool, input, options = {} } = await req.json();

    if (!tool || !input) {
      return new Response(JSON.stringify({ error: "Missing tool or input" }), {
        status: 400,
        headers: { ...corsHeaders, "Content-Type": "application/json" },
      });
    }

    // Check usage limits for free users
    const { data: subscription } = await supabaseClient
      .from("subscriptions")
      .select("status")
      .eq("user_id", user.id)
      .in("status", ["active", "trialing"])
      .limit(1)
      .single();

    const isPro = !!subscription;

    if (!isPro) {
      const today = new Date();
      today.setHours(0, 0, 0, 0);

      const { count } = await supabaseClient
        .from("usage_logs")
        .select("*", { count: "exact", head: true })
        .eq("user_id", user.id)
        .eq("tool", tool)
        .gte("created_at", today.toISOString());

      if ((count || 0) >= 3) {
        return new Response(JSON.stringify({ error: "Daily usage limit reached. Upgrade to Pro for unlimited access." }), {
          status: 429,
          headers: { ...corsHeaders, "Content-Type": "application/json" },
        });
      }
    }

    const systemPrompt = buildPrompt(tool, options);
    const startTime = Date.now();

    let llmResult;
    try {
      llmResult = await callOpenAI(systemPrompt, input);
    } catch (openaiError) {
      console.error("OpenAI failed, trying Anthropic:", openaiError);
      if (!ANTHROPIC_API_KEY) throw openaiError;
      llmResult = await callAnthropic(systemPrompt, input);
    }

    const processingTime = (Date.now() - startTime) / 1000;

    let parsed;
    try {
      parsed = JSON.parse(llmResult.content);
    } catch {
      parsed = { result: llmResult.content };
    }

    // Log usage
    await supabaseClient.from("usage_logs").insert({
      user_id: user.id,
      tool,
      input_text: input.substring(0, 5000),
      output_text: llmResult.content.substring(0, 5000),
      tokens_used: llmResult.tokensUsed,
      provider: llmResult.provider,
    });

    const response = {
      ...parsed,
      metadata: {
        provider: llmResult.provider,
        tokensUsed: llmResult.tokensUsed,
        processingTime,
      },
    };

    return new Response(JSON.stringify(response), {
      headers: { ...corsHeaders, "Content-Type": "application/json" },
    });

  } catch (error) {
    console.error("Process tool error:", error);
    return new Response(JSON.stringify({ error: error.message || "Internal server error" }), {
      status: 500,
      headers: { ...corsHeaders, "Content-Type": "application/json" },
    });
  }
});
